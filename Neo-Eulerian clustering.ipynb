{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neo-Eulerian clustering\n",
    "\n",
    "Duncan has a few datasets he's been working on with Robert that could benefit from a clustering approach. We've decided to run with DBSCAN as it's n-cluster agnostic and suitable for the data.\n",
    "\n",
    "1. Load in the euler-angle data\n",
    "2. Convert to quaternions\n",
    "3. Calculate grain boundaries (defined as boundaries with more than 5 degree mistilt)\n",
    "4. Compute homochoric (distance-preserving) representation\n",
    "5. Cluster using DBSCAN\n",
    "6. Means back to quaternions\n",
    "7. Project into fundamental zone\n",
    "8. Check overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from math import acos, pi\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from transforms3d.euler import euler2quat\n",
    "from transforms3d.quaternions import qmult, qinverse, quat2axangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/bm424/Desktop/upload_scripts_apollo/case_study_1_bainite_data.ctf') as f:\n",
    "    lines = f.readlines()\n",
    "lines = lines[17:]  # The first few lines are descriptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each line, split by tab stop and take the 5-7 columns inclusive.\n",
    "data = np.radians(np.array([line.split('\\t')[5:8] for line in lines]).astype(float))\n",
    "# The data appears to be doubled somehow, so just take the first half.\n",
    "data = data.reshape(223, 1190, 3)[:, :595, :].reshape(-1, 3)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual representation using the first Euler angle\n",
    "plt.imshow(data.reshape(223, 595, 3)[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to quaternions. This is slow as 'euler2quat' only operates on one row at a time.\n",
    "data_quat = np.array([euler2quat(*d, axes='rzyz') for d in data]).reshape(223, 595, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertical misorientation angles\n",
    "v = np.arccos(np.square(np.sum(data_quat[1:] * data_quat[:-1], axis=2)) * 2 - 1)[:, :-1]\n",
    "# Grain boundaries picked out where the angle is greater than 5 degrees\n",
    "plt.figure()\n",
    "plt.imshow(v > 0.0873)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal misorientation angles\n",
    "h = np.arccos(np.square(np.sum(data_quat[:, 1:] * data_quat[:, :-1], axis=2)) * 2 - 1)[:-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity just consider vertical ones. (There's more of them)\n",
    "to_compare = zip(data_quat[:-1, :-1][v > 0.0873], data_quat[1:, 1:][v > 0.0873])\n",
    "\n",
    "# Compute misorientation quaternions\n",
    "misorientations = np.array([qmult(q2, qinverse(q1)) for q1, q2 in to_compare])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If computing distance matrix, need a subset of the data for the sake of RAM\n",
    "# random_indices = np.random.choice(np.arange(len(misorientations)), 20000)\n",
    "# misorientations = misorientations[random_indices]\n",
    "# dmatrix = np.arccos(np.round(np.square(np.einsum('ik,jk->ij', misorientations, misorientations)), 8) * 2 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = np.array([quat2axangle(d)[0] for d in misorientations])\n",
    "angles = np.array([quat2axangle(d)[1] for d in misorientations])\n",
    "radius = (0.75*(angles - np.sin(angles)))**(1/3)  # Homochoric scaling. Note there is no inverse for this '>_<\n",
    "rf = axes * radius[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = DBSCAN(eps=0.03, min_samples=80).fit_predict(rf)  # Play with parameters - there are a lot of clusters on different scales\n",
    "print(len(set(labels)))  # N clusters found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise in 3d\n",
    "ax = plt.figure().add_subplot(111, projection='3d', aspect='equal')\n",
    "for label in set(labels):\n",
    "    if label < 0:  # Plot the 'noise' cluster separately\n",
    "        r = rf[labels == label]\n",
    "        ax.scatter(r[:, 0], r[:, 1], r[:, 2], s=0.1, c='k')\n",
    "        continue\n",
    "    r = rf[labels==label]\n",
    "    ax.scatter(r[:, 0], r[:, 1], r[:, 2], s=1)\n",
    "ax.set_xlim(-0.4, 0.4)\n",
    "ax.set_ylim(-0.4, 0.4)\n",
    "ax.set_zlim(-0.4, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the clusters more easily by taking a slice near the x plane \n",
    "ax = plt.figure().add_subplot(111, aspect='equal')\n",
    "slicer = np.abs(rf[:, 0]) < 0.05\n",
    "rf_slice = rf[slicer]\n",
    "labels_slice = labels[slicer]\n",
    "for label in set(labels_slice):\n",
    "    if label == -1:\n",
    "        r = rf_slice[labels_slice == label]\n",
    "        plt.scatter(r[:, 1], r[:, 2], s=0.2, c='k')\n",
    "        continue\n",
    "    r = rf_slice[labels_slice == label]\n",
    "    plt.scatter(r[:, 1], r[:, 2], s=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plenty of clusters are found with the above parameters, but many small ones aren't. I think each individual grain boundary has its own little cluster, demonstrating the importance of applying the symmetry reduction *before* doing this kind of clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the real space distribution of clusters\n",
    "blank = np.zeros_like(v)\n",
    "blank[v > 0.0873] = labels + 2\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(blank)\n",
    "plt.colorbar(label='cluster index')\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the misorientation quaternions associated with each cluster\n",
    "misorientations_sorted = {label: misorientations[labels==label] for label in set(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misorientations_labeled = np.vstack(np.hstack((np.ones((len(misorientations_sorted[label]), 1))*label, misorientations_sorted[label])) for label in misorientations_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('misorientations_labeled.txt', misorientations_labeled, fmt=['%03.2i', '%09.6f', '%09.6f', '%09.6f', '%09.6f'], delimiter='\\t\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do:\n",
    "\n",
    "- Apply symmetry operations. Probably should be done before clustering based on the above although there is in principle no problem with finding loads of clusters and compressing them afterwards.\n",
    "- Be more intelligent with finding the high orientations\n",
    "- Implement quaternion averaging (It should be possible simply to take the mean of the homochoric points but there is no inverse of $\\omega - \\sin\\omega$ to get back to axis-angle representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
